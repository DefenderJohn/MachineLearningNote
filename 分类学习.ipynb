{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 分类学习\n",
    "## 决策树 Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 绘制Mermaid图表的工具，来自 https://gist.github.com/MLKrisJohnson/2d2df47879ee6afd3be9d6788241fe99\n",
    "import base64\n",
    "from IPython.display import Image, display\n",
    "\n",
    "def mm_ink(graphbytes):\n",
    "  \"\"\"Given a bytes object holding a Mermaid-format graph, return a URL that will generate the image.\"\"\"\n",
    "  base64_bytes = base64.b64encode(graphbytes)\n",
    "  base64_string = base64_bytes.decode(\"ascii\")\n",
    "  return \"https://mermaid.ink/img/\" + base64_string\n",
    "\n",
    "def mm_display(graphbytes):\n",
    "  \"\"\"Given a bytes object holding a Mermaid-format graph, display it.\"\"\"\n",
    "  display(Image(url=mm_ink(graphbytes)))\n",
    "\n",
    "def mm(graph):\n",
    "  \"\"\"Given a string containing a Mermaid-format graph, display it.\"\"\"\n",
    "  graphbytes = graph.encode(\"ascii\")\n",
    "  mm_display(graphbytes)\n",
    "\n",
    "def mm_link(graph):\n",
    "  \"\"\"Given a string containing a Mermaid-format graph, return URL for display.\"\"\"\n",
    "  graphbytes = graph.encode(\"ascii\")\n",
    "  return mm_ink(graphbytes)\n",
    "  \n",
    "def mm_path(path):\n",
    "  \"\"\"Given a path to a file containing a Mermaid-format graph, display it\"\"\"\n",
    "  with open(path, 'rb') as f:\n",
    "    graphbytes = f.read()\n",
    "  mm_display(graphbytes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 概要\n",
    "决策树是主要用于分类和回归任务的数据结构，它由节点和连接这两部分组成。\n",
    " - 节点：每个节点都代表了一个数据标签\n",
    " - 连接：由父节点连接到子节点的标签特征。\n",
    "我们下面会用一个简单的样例来解释决策树。\n",
    "\n",
    "首先，我们需要一些数据，这些数据应该具备自己的数据标签和观察到的特征。这里我们以“学生是否通过考试”为案例，示例如下：\n",
    "| 学习时长(StudyDuration:H/M/L) | 是否复习(Reviewed:Y/N) | 睡眠质量(SleepQuality:G/A(verage)/P(oor)) | 是否通过考试(Pass/Fail) |\n",
    "|--------|--------|--------|-----------|\n",
    "| 高     | 是    | 好     | 是        |\n",
    "| 高     | 否    | 好     | 否        |\n",
    "| 中     | 是    | 一般   | 是        |\n",
    "| 低     | 否    | 差     | 否        |\n",
    "| 低     | 是    | 好     | 否        |\n",
    "| 低     | 是    | 一般   | 是        |\n",
    "| 中     | 否    | 差     | 否        |\n",
    "| 高     | 是    | 一般   | 是        |\n",
    "\n",
    "随后，我们需要选取**特征**和**目标变量**。\n",
    " - 特征：特征指的是我们用来进行判断决策的指标，比如上表中的学习时长，是否复习等\n",
    " - 目标变量：目标变量指的是我们需要预测的指标，只能有一个，就是上表里的是否通过考试\n",
    "接下来我们需要对这张数据表进行观察并构建一棵决策树。构建决策树时我们需要使用一些算法来确定应该以什么特征进行判断决策，但在这里先暂时忽略，就以最基础的直觉进行构建，如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://mermaid.ink/img/Z3JhcGggVEQKICAgIEFbU3R1ZHlEdXJhdGlvbl0gLS0+fEh8IEIxW1Jldmlld2VkXQogICAgQSAtLT58TXwgQjJbUmV2aWV3ZWRdCiAgICBBIC0tPnxMfCBCM1tSZXZpZXdlZF0KICAgIEIxIC0tPnxZfCBDMVtTUV0KICAgIEIxIC0tPnxOfCBDMltTUV0KICAgIEIyIC0tPnxZfCBDM1tTUV0KICAgIEIyIC0tPnxOfCBDNFtTUV0KICAgIEIzIC0tPnxZfCBDNVtTUV0KICAgIEIzIC0tPnxOfCBDNltTUV0KICAgIEMxIC0tPnxHfCBEMVtQYXNzXQogICAgQzEgLS0+fEF8IEQyW1Bhc3NdCiAgICBDMSAtLT58UHwgRDNbRmFpbF0KICAgIEMyIC0tPnxHfCBENFtGYWlsXQogICAgQzIgLS0+fEF8IEQ1W0ZhaWxdCiAgICBDMiAtLT58UHwgRDZbRmFpbF0KICAgIEMzIC0tPnxHfCBEN1tGYWlsXQogICAgQzMgLS0+fEF8IEQ4W1Bhc3NdCiAgICBDMyAtLT58UHwgRDlbRmFpbF0KICAgIEM0IC0tPnxHfCBEMTBbRmFpbF0KICAgIEM0IC0tPnxBfCBEMTFbRmFpbF0KICAgIEM0IC0tPnxQfCBEMTJbRmFpbF0KICAgIEM1IC0tPnxHfCBEMTNbRmFpbF0KICAgIEM1IC0tPnxBfCBEMTRbUGFzc10KICAgIEM1IC0tPnxQfCBEMTVbRmFpbF0KICAgIEM2IC0tPnxHfCBEMTZbRmFpbF0KICAgIEM2IC0tPnxBfCBEMTdbUGFzc10KICAgIEM2IC0tPnxQfCBEMThbRmFpbF0=\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with open('分类学习/决策树1.data', 'r', encoding='utf-8') as file:\n",
    "    mm(file.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在这里，我们展示了一个纯粹直觉构建的决策树图表。当我们拿到一个新的数据，比如下表时，就可以根据上面构建的决策树进行预测。\n",
    "| 学习时长 | 是否复习 | 睡眠质量 | 是否通过考试 |\n",
    "|--------|--------|--------|-----------|\n",
    "| 低     | 否    | 好     | ？        |\n",
    "\n",
    "我们根据新的数据和决策树，首先判断学习时长，于是走L路线，然后判断是否复习，走H路线，随后判断睡眠质量，走G路线，最后得到的结果就直接是G边对应的叶子节点，也即Fail。于是我们就可以预测在这种情况下这位考生不能通过考试。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://mermaid.ink/img/Z3JhcGggVEQKICAgIEFbU3R1ZHlEdXJhdGlvbl0gLS0+fEh8IEIxW1Jldmlld2VkXQogICAgQSAtLT58TXwgQjJbUmV2aWV3ZWRdCiAgICBBIC0tPnxMfCBCM1tSZXZpZXdlZF0KICAgIEIxIC0tPnxZfCBDMVtTUV0KICAgIEIxIC0tPnxOfCBDMltTUV0KICAgIEIyIC0tPnxZfCBDM1tTUV0KICAgIEIyIC0tPnxOfCBDNFtTUV0KICAgIEIzIC0tPnxZfCBDNVtTUV0KICAgIEIzIC0tPnxOfCBDNltTUV0KICAgIEMxIC0tPnxHfCBEMVtQYXNzXQogICAgQzEgLS0+fEF8IEQyW1Bhc3NdCiAgICBDMSAtLT58UHwgRDNbRmFpbF0KICAgIEMyIC0tPnxHfCBENFtGYWlsXQogICAgQzIgLS0+fEF8IEQ1W0ZhaWxdCiAgICBDMiAtLT58UHwgRDZbRmFpbF0KICAgIEMzIC0tPnxHfCBEN1tGYWlsXQogICAgQzMgLS0+fEF8IEQ4W1Bhc3NdCiAgICBDMyAtLT58UHwgRDlbRmFpbF0KICAgIEM0IC0tPnxHfCBEMTBbRmFpbF0KICAgIEM0IC0tPnxBfCBEMTFbRmFpbF0KICAgIEM0IC0tPnxQfCBEMTJbRmFpbF0KICAgIEM1IC0tPnxHfCBEMTNbRmFpbF0KICAgIEM1IC0tPnxBfCBEMTRbUGFzc10KICAgIEM1IC0tPnxQfCBEMTVbRmFpbF0KICAgIEM2IC0tPnxHfCBEMTZbRmFpbF0KICAgIEM2IC0tPnxBfCBEMTdbUGFzc10KICAgIEM2IC0tPnxQfCBEMThbRmFpbF0KCiAgICBjbGFzc0RlZiByZWQgZmlsbDojZjY2LHN0cm9rZTojZjY2OwogICAgY2xhc3MgQjMsQzYsRDE2IHJlZDsKICAgIGxpbmtTdHlsZSAyIHN0cm9rZTojZjY2LHN0cm9rZS13aWR0aDoycHg7CiAgICBsaW5rU3R5bGUgOCBzdHJva2U6I2Y2NixzdHJva2Utd2lkdGg6MnB4OwogICAgbGlua1N0eWxlIDI0IHN0cm9rZTojZjY2LHN0cm9rZS13aWR0aDoycHg7\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with open('分类学习/决策树2.data', 'r', encoding='utf-8') as file:\n",
    "    mm(file.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ID3算法（第三代迭代二叉树算法）\n",
    "### 概述\n",
    "我们在实际的模型学习里当然不可能靠人的直觉来判断决策树应该以什么边和节点来构建，所以我们必须要有一个算法来代替直觉找到“最符合数据分布”的决策树。在这里，我们会使用ID3算法来进行处理。\n",
    "\n",
    "迭代二叉树算法的计算原理是对整个数据集进行“分裂”，也就是基于标签能提供的信息增益对整个数据集进行拆分。在选择出信息增益最大的标签之后，就会将数据集按这个标签进行分割，随后就像二叉树算法一样，对分割后的每一个子数据集重新执行这个算法，一直执行到所有标签全部被用来分割过一遍，或者达到预设的其他终止条件为止。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 熵 Entropy\n",
    "在上文中我们提到了**信息增益**这个关键词，在ID3算法里，信息增益指的就是数据集的信息熵。\n",
    "\n",
    "从直观上理解，信息熵可以这么解释：当一个数据集里元素分布得越均匀时，这个数据集的熵就越高。反之，如果这个数据集里元素分布得不均匀，那么这个数据集的熵就越低。极端情况是，如果一个数据集中所有元素都分布在同一个类别，那么这个数据集的熵就是0，也就是熵此时最低。\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
